### Notion에서 데이터 추출 > 임베딩 > 벡터 DB(Chroma)저장
1. Notion에서 데이터 가져오기

### 벡터 모델과 생성형 AI로 의도분류 차이
#### 벡터 모델만 사용하는 경우
- 문장을 임베딩해서 저장하고, 나중에 비슷한 문장이 오면 top-k 검색해서 보여주자
- 입력 문장을 벡터화 > 벡터 DB에서 유사도 검색
- 특징
  - 검색 품질이 임베딩 모델 성능에 따라 결정
  - 검색 결과 그대로 보여줌 > 생성형 응답 아님
  - 복잡한 질의는 처리 불가=

#### 생성형 AI + RAG 구조
- 질문이 오면, 어떤 의도인지 분류하고 > 관련 문서 검색(Retrieval) > 생성형 AI 가 답을 생성
- 특징
  - 사용자의 질문 의도를 파악하고 그에 맞는 context를 선택적으로 조합


### 전체 흐름
1. 사용자가 질문을 입력
2. 의도 분류
3. 질문을 벡터화해서 벡터 DB에서 관련 문서 top-k 검색
4. 검색된 문서를 문맥(context)로 묶음
5. 질문 + 문맥 -> 생성형 AI 에 전달
6. 자연어 답변 생성 및 반환


+ Notion Version
1. Notion 에서 content 추출 (페이지 or DB)
2. 텍스트 전처리 (chunking)
3. 임베딩 처리
4. 벡터 DB 저장 (Chroma 등)
5. 사용자 질문
6. 질문 임베딩 -> 유사 context 검색
7. GPT에게 context + 질문을 넘겨 응답 생성

+ Blog Version
🔍 Step 1: 네이버 블로그 크롤링 + 말투/스타일 벡터화
🧠 Step 2: 벡터 DB에 저장 (ex. Chroma or Qdrant)
🧑 Step 3: Slack에서 사용자가 후기 요청
🤖 Step 4: 슬랙 봇이 해당 요청을 FastAPI로 전달
🔁 Step 5: 프롬프트 생성
현재 후기 요청 (ex. “빽다방 베이커리 다녀옴”)
과거 글 스타일 (RAG 기반)
✍️ Step 6: LLM이 스타일 반영한 블로그 포스트 생성
🪄 Step 7: Slack으로 응답

 + 파서 붙이기
  ### 파서란
  - Notion같은 문서에서 텍스트만 추출하는게 아니라 문서 구조(계층, 제목, 표, 코드,블록 등)을 이해해서 **의미 단위**로 쪼개는 도구
 + ngrok 사용하기